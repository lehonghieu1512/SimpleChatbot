{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\envs\\py35\\lib\\site-packages\\gensim\\utils.py:865: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import doc2vec\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "import gensim\n",
    "from collections import namedtuple\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "from keras.models import model_from_json\n",
    "from keras.models import load_model\n",
    "import random\n",
    "from keras import optimizers\n",
    "import re\n",
    "import gensim.models as g\n",
    "import logging\n",
    "import numpy as np\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some necessary links of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chatbot_data='Dataset\\\\data.json_responses.json'#link leads to the file containing data for chatbot\n",
    "doc2vec_data='Dataset\\data11_9_.txt'#link leads to the file containing data for doc2vec model, I named it as data11_9_ according to the date I made this data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data for chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open(chatbot_data,encoding='utf8') as json_data:\n",
    "    intents = json.load(json_data)\n",
    "content=intents['intents']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create one hot vector for each class (we have 114 classes in total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "one_hot=np.zeros((len(content),len(content)))\n",
    "one_hot[range(len(one_hot)),range(len(one_hot))]=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert rough data which is text type into one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rough_text=[]\n",
    "Y=[]\n",
    "for i in range(len(content)):\n",
    "    content[i]['patterns']\n",
    "    l=content[i]['patterns']\n",
    "    for j in range(len(l)):\n",
    "        Y.append(one_hot[i])\n",
    "        rough_text.append(l[j].lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create para2vec model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare some necessary stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#doc2vec parameters\n",
    "vector_size = 120\n",
    "window_size = 4\n",
    "min_count = 1\n",
    "sampling_threshold = 1e-5\n",
    "negative_size = 5\n",
    "train_epoch = 150\n",
    "dm = 0\n",
    "worker_count = 1 #number of parallel processes\n",
    "\n",
    "def trans(content):#convert content into taggedDocument type\n",
    "    result=[]\n",
    "    analyzedDocument = namedtuple('AnalyzedDocument', 'words tags')\n",
    "    for a,b in enumerate(content):\n",
    "        words = b.lower().split()\n",
    "        tags = [a]\n",
    "        result.append(gensim.models.doc2vec.TaggedDocument(gensim.utils.simple_preprocess(b), [a]))\n",
    "    return result\n",
    "\n",
    "p2v_content=[]\n",
    "with open(doc2vec_data,encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        p2v_content.append(line)\n",
    "p2v_content.extend(rough_text)\n",
    "utf8_content=trans(p2v_content)\n",
    "model = gensim.models.doc2vec.Doc2Vec(size=vector_size, window=window_size, min_count=min_count,seed=0, sample=sampling_threshold, workers=worker_count, hs=0, dm=dm, negative=negative_size, dbow_words=1, dm_concat=1,  iter=train_epoch)\n",
    "model.build_vocab(utf8_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create doc2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.01 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "246036"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time model.train(utf8_content, total_examples=model.corpus_count, epochs=model.iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Create a \"brain\" for chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_model(X,Y):\n",
    "    seed = 7\n",
    "    np.random.seed(seed)\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, input_dim=X.shape[1], activation='relu'))\n",
    "    model.add(Dense(300, activation='relu'))\n",
    "    model.add(Dense(250, activation='relu'))\n",
    "    model.add(Dense(340, activation='relu'))\n",
    "    model.add(Dense(390, activation='relu'))\n",
    "    model.add(Dense(Y.shape[1], activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "    # Fit the model\n",
    "    model.fit(X, Y, epochs=1200, batch_size=10,shuffle=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get vectors to feed neuronNet from texts via doc2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1888, 120) (1888, 110)\n"
     ]
    }
   ],
   "source": [
    "X=[]    \n",
    "for i in range(len(rough_text)):\n",
    "    model.random.seed(7)\n",
    "    vec=model.infer_vector(re.sub('\\?','',rough_text[i]).lower().split(' '))\n",
    "    X.append(vec)\n",
    "Y=np.array(Y)\n",
    "X=np.array(X)\n",
    "print (X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create neuron network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "1888/1888 [==============================] - 2s - loss: 0.0090 - acc: 0.0185     \n"
     ]
    }
   ],
   "source": [
    "neu_model=create_model(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction step for forming answer for users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predictions(quest):\n",
    "    model.random.seed(7)\n",
    "    vec=np.array(model.infer_vector(quest.split(' '))).reshape(1,-1)\n",
    "    out_put=neu_model.predict(vec)\n",
    "    return content[np.argmax(out_put)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_answer(quest):\n",
    "    answer=predictions(quest)#this is a list containing a set of answers\n",
    "    a=random.randint(0,len(answer)-1)\n",
    "    return answer['responses'][a]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input your question into the blank in the function below and it will return an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'có em đây chuyện gì rồi sẽ qua thôi'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_answer(\"chào\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
